services:
  tgi:
    image: ghcr.io/huggingface/text-generation-inference:latest
    command: --model-id /data/llama_finetuned/gptqmodel_4bit --quantize gptq
    restart: always 
    ports:
      - "8080:80"
    volumes:
      - medimaven_volume:/data:ro
    networks:
      - medimaven-network
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 60s
      timeout: 30s
      retries: 5

    logging:
      driver: awslogs
      options:
        awslogs-group: /medimaven/containers
        awslogs-region: us-east-1
        awslogs-create-group: "true"

    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: [gpu]

  rag-api:
    image: phade160/medimaven-rag-api:v1.0.0
    restart: always
    ports:
      - "8000:8000"
    volumes:
      - medimaven_volume:/app/models:ro
    networks:
      - medimaven-network
    environment:
      - TGI_API_URL=http://tgi:80
    env_file:
      - .env
    depends_on:
      - tgi
    logging:
      driver: awslogs
      options:
        awslogs-group: /medimaven/containers
        awslogs-region: us-east-1
        awslogs-create-group: "true"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 5m
      timeout: 120s
      retries: 5

networks:
  medimaven-network:
    driver: bridge


volumes:
  medimaven_volume:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./models